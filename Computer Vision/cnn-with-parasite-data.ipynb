{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/notsau/cnn-with-parasite-data?scriptVersionId=161440885\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"#Veri çok büyük 5000 tanesini alıp yükledik","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport shutil\n\n# Veri seti yolu\ndata_dir = '/kaggle/input/cell-images-for-detecting-malaria/cell_images'\nhedef_dir = 'veri'\n\n# Rastgele fotoğrafların sayısı\nsecilen_sayi = 5000\n\n# Parasitized fotoğrafların dizini\nparasitized_dir = os.path.join(data_dir, 'Parasitized')\n\n# Uninfected fotoğrafların dizini\nuninfected_dir = os.path.join(data_dir, 'Uninfected')\n\n# Hedef dizinler\nhedef_parasitized_dir = os.path.join(hedef_dir, 'parazitli')\nhedef_uninfected_dir = os.path.join(hedef_dir, 'parazitsiz')\n\n# Hedef dizinleri oluşturma\nos.makedirs(hedef_parasitized_dir, exist_ok=True)\nos.makedirs(hedef_uninfected_dir, exist_ok=True)\n\n# Parasitized fotoğrafları rastgele seçme\nparasitized_fotograflar = os.listdir(parasitized_dir)\nsecilen_parasitizedler = random.sample(parasitized_fotograflar, secilen_sayi)\n\n# Uninfected fotoğrafları rastgele seçme\nuninfected_fotograflar = os.listdir(uninfected_dir)\nsecilen_uninfectedler = random.sample(uninfected_fotograflar, secilen_sayi)\n\n# Parasitized fotoğrafları hedef dizine kopyalama\nfor parasitized in secilen_parasitizedler:\n    kaynak = os.path.join(parasitized_dir, parasitized)\n    hedef = os.path.join(hedef_parasitized_dir, parasitized)\n    shutil.copyfile(kaynak, hedef)\n\n# Uninfected fotoğrafları hedef dizine kopyalama\nfor uninfected in secilen_uninfectedler:\n    kaynak = os.path.join(uninfected_dir, uninfected)\n    hedef = os.path.join(hedef_uninfected_dir, uninfected)\n    shutil.copyfile(kaynak, hedef)","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Test/Eğitim Dosyaları Oluşturma","metadata":{},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport shutil\n\n# Veri seti dizini\nbase_dir = 'veri'\ntrain_dir = os.path.join(base_dir, 'egitim')\ntest_dir = os.path.join(base_dir, 'test')\n\n# Eğitim ve test dizinlerini oluşturma\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)\n\n# Sınıf isimleri\nclass_names = ['parazitli', 'parazitsiz']\n\n# Eğitim ve test veri setlerini oluşturma\nfor class_name in class_names:\n    class_dir = os.path.join(base_dir, class_name)\n    train_class_dir = os.path.join(train_dir, class_name)\n    test_class_dir = os.path.join(test_dir, class_name)\n    os.makedirs(train_class_dir, exist_ok=True)\n    os.makedirs(test_class_dir, exist_ok=True)\n    \n    # Sınıfa ait tüm fotoğrafları elde etme\n    all_files = os.listdir(class_dir)\n    random.shuffle(all_files)\n    \n    # Eğitim ve test veri setlerine fotoğrafları kopyalama\n    split_index = int(0.8 * len(all_files))  # %80 eğitim, %20 test\n    train_files = all_files[:split_index]\n    test_files = all_files[split_index:]\n    \n    for train_file in train_files:\n        src = os.path.join(class_dir, train_file)\n        dst = os.path.join(train_class_dir, train_file)\n        shutil.copyfile(src, dst)\n        \n    for test_file in test_files:\n        src = os.path.join(class_dir, test_file)\n        dst = os.path.join(test_class_dir, test_file)\n        shutil.copyfile(src, dst)","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Veri seti yolu\nbase_dir = 'veri'\ntrain_dir = os.path.join(base_dir, 'egitim')\ntest_dir = os.path.join(base_dir, 'test')\n\n# Veri ön işleme\nimage_size = (150, 150)\nbatch_size = 64\n\n# Eğitim veri seti için veri artırma ve normalizasyon\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\n# Test veri seti için sadece normalizasyon\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Eğitim ve test veri setlerini yükleyin ve ön işleyin\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Model oluşturma\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Model derleme\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Model eğitimi\nepochs = 1\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    epochs=epochs,\n    validation_data=test_generator,\n    validation_steps=test_generator.samples // batch_size\n)","metadata":{},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"WARNING:tensorflow:From C:\\Users\\slymn\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\n\n\nFound 19177 images belonging to 2 classes.\n\nFound 7936 images belonging to 2 classes.\n\nWARNING:tensorflow:From C:\\Users\\slymn\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\n\n\nWARNING:tensorflow:From C:\\Users\\slymn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\n\n\nWARNING:tensorflow:From C:\\Users\\slymn\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n\n\nWARNING:tensorflow:From C:\\Users\\slymn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n\n\n\nWARNING:tensorflow:From C:\\Users\\slymn\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n\n\n\n299/299 [==============================] - 394s 1s/step - loss: 0.4334 - accuracy: 0.7995 - val_loss: 0.2074 - val_accuracy: 0.9286\n"}]}]}